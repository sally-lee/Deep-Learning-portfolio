{"cells":[{"cell_type":"markdown","metadata":{"id":"b518b04cbfe0"},"source":["##### Copyright 2020 The TensorFlow Authors."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","execution":{"iopub.execute_input":"2021-11-12T19:46:50.741979Z","iopub.status.busy":"2021-11-12T19:46:50.741267Z","iopub.status.idle":"2021-11-12T19:46:50.743612Z","shell.execute_reply":"2021-11-12T19:46:50.743978Z"},"id":"906e07f6e562"},"outputs":[],"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"6e083398b477"},"source":["# Working with preprocessing layers"]},{"cell_type":"markdown","metadata":{"id":"64010bd23c2e"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/preprocessing_layers\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/snapshot-keras/site/en/guide/keras/preprocessing_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/keras-team/keras-io/blob/master/guides/preprocessing_layers.py\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/keras/preprocessing_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"b1d403f04693"},"source":["## Keras preprocessing\n","\n","The Keras preprocessing layers API allows developers to build Keras-native input\n","processing pipelines. These input processing pipelines can be used as independent\n","preprocessing code in non-Keras workflows, combined directly with Keras models, and\n","exported as part of a Keras SavedModel.\n","\n","With Keras preprocessing layers, you can build and export models that are truly\n","end-to-end: models that accept raw images or raw structured data as input; models that\n","handle feature normalization or feature value indexing on their own."]},{"cell_type":"markdown","metadata":{"id":"313360fa9024"},"source":["## Available preprocessing\n","\n","### Text preprocessing\n","\n","- `tf.keras.layers.TextVectorization`: turns raw strings into an encoded\n","  representation that can be read by an `Embedding` layer or `Dense` layer.\n","\n","### Numerical features preprocessing\n","\n","- `tf.keras.layers.Normalization`: performs feature-wise normalize of\n","  input features.\n","- `tf.keras.layers.Discretization`: turns continuous numerical features\n","  into integer categorical features.\n","\n","### Categorical features preprocessing\n","\n","- `tf.keras.layers.CategoryEncoding`: turns integer categorical features\n","  into one-hot, multi-hot, or count dense representations.\n","- `tf.keras.layers.Hashing`: performs categorical feature hashing, also known as\n","  the \"hashing trick\".\n","- `tf.keras.layers.StringLookup`: turns string categorical values an encoded\n","  representation that can be read by an `Embedding` layer or `Dense` layer.\n","- `tf.keras.layers.IntegerLookup`: turns integer categorical values into an\n","  encoded representation that can be read by an `Embedding` layer or `Dense`\n","  layer.\n","\n","\n","### Image preprocessing\n","\n","These layers are for standardizing the inputs of an image model.\n","\n","- `tf.keras.layers.Resizing`: resizes a batch of images to a target size.\n","- `tf.keras.layers.Rescaling`: rescales and offsets the values of a batch of\n","  image (e.g. go from inputs in the `[0, 255]` range to inputs in the `[0, 1]`\n","  range.\n","- `tf.keras.layers.CenterCrop`: returns a center crop of a batch of images.\n","\n","### Image data augmentation\n","\n","These layers apply random augmentation transforms to a batch of images. They\n","are only active during training.\n","\n","- `tf.keras.layers.RandomCrop`\n","- `tf.keras.layers.RandomFlip`\n","- `tf.keras.layers.RandomTranslation`\n","- `tf.keras.layers.RandomRotation`\n","- `tf.keras.layers.RandomZoom`\n","- `tf.keras.layers.RandomHeight`\n","- `tf.keras.layers.RandomWidth`\n","- `tf.keras.layers.RandomContrast`"]},{"cell_type":"markdown","metadata":{"id":"c923e41fb1b4"},"source":["## The `adapt()` method\n","\n","Some preprocessing layers have an internal state that can be computed based on\n","a sample of the training data. The list of stateful preprocessing layers is:\n","\n","- `TextVectorization`: holds a mapping between string tokens and integer indices\n","- `StringLookup` and `IntegerLookup`: hold a mapping between input values and integer\n","indices.\n","- `Normalization`: holds the mean and standard deviation of the features.\n","- `Discretization`: holds information about value bucket boundaries.\n","\n","Crucially, these layers are **non-trainable**. Their state is not set during training; it\n","must be set **before training**, either by initializing them from a precomputed constant,\n","or by \"adapting\" them on data.\n","\n","You set the state of a preprocessing layer by exposing it to training data, via the\n","`adapt()` method:"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T19:46:50.752341Z","iopub.status.busy":"2021-11-12T19:46:50.751708Z","iopub.status.idle":"2021-11-12T19:46:54.423686Z","shell.execute_reply":"2021-11-12T19:46:54.424124Z"},"id":"4cac6bd80812","executionInfo":{"status":"ok","timestamp":1665707679298,"user_tz":-540,"elapsed":1057,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"code","source":["data = np.array([[0.1, 0.2, 0.3], [0.8, 0.9, 1.0], [1.5, 1.6, 1.7],])\n","layer = layers.Normalization()\n","layer.adapt(data)\n","normalized_data = layer(data)\n","\n","print(\"Features mean: %.2f\" % (normalized_data.numpy().mean()))\n","print(\"Features std: %.2f\" % (normalized_data.numpy().std()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"izvyLF8F4eLB","executionInfo":{"status":"ok","timestamp":1665640042914,"user_tz":-540,"elapsed":328,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"17fa80e8-39b8-4abb-fd91-c7793d9d8759"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Features mean: -0.00\n","Features std: 1.00\n"]}]},{"cell_type":"markdown","metadata":{"id":"d43b8246b8a3"},"source":["The `adapt()` method takes either a Numpy array or a `tf.data.Dataset` object. In the\n","case of `StringLookup` and `TextVectorization`, you can also pass a list of strings:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T19:46:54.433002Z","iopub.status.busy":"2021-11-12T19:46:54.432318Z","iopub.status.idle":"2021-11-12T19:46:54.527457Z","shell.execute_reply":"2021-11-12T19:46:54.527857Z"},"id":"48d95713348a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665644936250,"user_tz":-540,"elapsed":432,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"d533ed62-2a85-4b13-f908-825e9e53356d"},"outputs":[{"output_type":"stream","name":"stdout","text":["['', '[UNK]', 'ῥ᾽', 'ἔλθωσι', 'οἵ', 'μὲν', 'διὰ', 'αἱ', 'ὅτε', 'ὄνειροι', 'ὀνείρων', 'ἴδηται', 'ἦ', 'ἔτυμα', 'ἔπε᾽', 'ἐλεφαίρονται', 'ἐλέφαντος', 'ἐλέφαντι', 'ἀνθρώποισι', 'ἀμενηνῶν', 'ἀμήχανοι', 'ἀκριτόμυθοι', 'ἀκράαντα', 'φέροντες', 'τῶν', 'τοι', 'τις', 'τι', 'τετεύχαται', 'τελείεται', 'τε', 'πύλαι', 'πριστοῦ', 'πάντα', 'οὐδέ', 'οἳ', 'οἱ', 'ξεῖν᾽', 'ξεστῶν', 'μέν', 'κ᾽', 'κραίνουσι', 'κεράων', 'κεράεσσι', 'κέν', 'θύραζε', 'εἰσὶν', 'δ᾽', 'δὲ', 'δοιαὶ', 'γὰρ', 'γίγνοντ᾽', 'γάρ', 'βροτῶν']\n","54\n","tf.Tensor(\n","[[37 12 25  5  9 20 21  0  0]\n"," [51 34 27 33 29 18  0  0  0]\n"," [49 52 30 31 19 46 10  0  0]\n"," [ 7  5 50 43 28  7 47 17  0]\n"," [24 35 39 40  3  6 32 16  0]\n"," [ 4  2 15 14 22 23  0  0  0]\n"," [36 48  6 38 42  3 45  0  0]\n"," [ 4  2 13 41 53  8 44 26 11]], shape=(8, 9), dtype=int64)\n"]}],"source":["data = [\n","    \"ξεῖν᾽, ἦ τοι μὲν ὄνειροι ἀμήχανοι ἀκριτόμυθοι\",\n","    \"γίγνοντ᾽, οὐδέ τι πάντα τελείεται ἀνθρώποισι.\",\n","    \"δοιαὶ γάρ τε πύλαι ἀμενηνῶν εἰσὶν ὀνείρων:\",\n","    \"αἱ μὲν γὰρ κεράεσσι τετεύχαται, αἱ δ᾽ ἐλέφαντι:\",\n","    \"τῶν οἳ μέν κ᾽ ἔλθωσι διὰ πριστοῦ ἐλέφαντος,\",\n","    \"οἵ ῥ᾽ ἐλεφαίρονται, ἔπε᾽ ἀκράαντα φέροντες:\",\n","    \"οἱ δὲ διὰ ξεστῶν κεράων ἔλθωσι θύραζε,\",\n","    \"οἵ ῥ᾽ ἔτυμα κραίνουσι, βροτῶν ὅτε κέν τις ἴδηται.\",\n","]\n","layer = layers.TextVectorization()\n","layer.adapt(data)\n","print(layer.get_vocabulary())\n","print(len(layer.get_vocabulary()))\n","vectorized_text = layer(data)\n","\n","print(vectorized_text)"]},{"cell_type":"markdown","metadata":{"id":"7619914dfb40"},"source":["In addition, adaptable layers always expose an option to directly set state via\n","constructor arguments or weight assignment. If the intended state values are known at\n","layer construction time, or are calculated outside of the `adapt()` call, they can be set\n","without relying on the layer's internal computation. For instance, if external vocabulary\n","files for the `TextVectorization`, `StringLookup`, or `IntegerLookup` layers already\n","exist, those can be loaded directly into the lookup tables by passing a path to the\n","vocabulary file in the layer's constructor arguments.\n","\n","Here's an example where we instantiate a `StringLookup` layer with precomputed vocabulary:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T19:46:54.533999Z","iopub.status.busy":"2021-11-12T19:46:54.533382Z","iopub.status.idle":"2021-11-12T19:46:54.537527Z","shell.execute_reply":"2021-11-12T19:46:54.537905Z"},"id":"9df56efc7f3b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665645032730,"user_tz":-540,"elapsed":318,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"d2544fbd-784d-4b56-981e-682415206763"},"outputs":[{"output_type":"stream","name":"stdout","text":["['[UNK]', 'a', 'b', 'c', 'd']\n","5\n","tf.Tensor(\n","[[1 3 4]\n"," [4 0 2]], shape=(2, 3), dtype=int64)\n"]}],"source":["vocab = [\"a\", \"b\", \"c\", \"d\"]\n","data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n","layer = layers.StringLookup(vocabulary=vocab)\n","print(layer.get_vocabulary())\n","print(len(layer.get_vocabulary()))\n","vectorized_data = layer(data)\n","print(vectorized_data)"]},{"cell_type":"markdown","metadata":{"id":"49cbfe135b00"},"source":["## Preprocessing data before the model or inside the model\n","\n","There are two ways you could be using preprocessing layers:\n","\n","**Option 1:** Make them part of the model, like this:\n","\n","```python\n","inputs = keras.Input(shape=input_shape)\n","x = preprocessing_layer(inputs)\n","outputs = rest_of_the_model(x)\n","model = keras.Model(inputs, outputs)\n","```\n","\n","With this option, preprocessing will happen on device, synchronously with the rest of the\n","model execution, meaning that it will benefit from GPU acceleration.\n","If you're training on GPU, this is the best option for the `Normalization` layer, and for\n","all image preprocessing and data augmentation layers.\n","\n","**Option 2:** apply it to your `tf.data.Dataset`, so as to obtain a dataset that yields\n","batches of preprocessed data, like this:\n","\n","```python\n","dataset = dataset.map(lambda x, y: (preprocessing_layer(x), y))\n","```\n","\n","With this option, your preprocessing will happen on CPU, asynchronously, and will be\n","buffered before going into the model.\n","In addition, if you call `dataset.prefetch(tf.data.AUTOTUNE)` on your dataset,\n","the preprocessing will happen efficiently in parallel with training:\n","\n","```python\n","dataset = dataset.map(lambda x, y: (preprocessing_layer(x), y))\n","dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","model.fit(dataset, ...)\n","```\n","\n","This is the best option for `TextVectorization`, and all structured data preprocessing\n","layers. It can also be a good option if you're training on CPU\n","and you use image preprocessing layers.\n","\n","**When running on TPU, you should always place preprocessing layers in the `tf.data` pipeline**\n","(with the exception of `Normalization` and `Rescaling`, which run fine on TPU and are commonly\n","used as the first layer is an image model)."]},{"cell_type":"markdown","metadata":{"id":"32f6d2a104b7"},"source":["## Benefits of doing preprocessing inside the model at inference time\n","\n","Even if you go with option 2, you may later want to export an inference-only end-to-end\n","model that will include the preprocessing layers. The key benefit to doing this is that\n","**it makes your model portable** and it **helps reduce the\n","[training/serving skew](https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew)**.\n","\n","When all data preprocessing is part of the model, other people can load and use your\n","model without having to be aware of how each feature is expected to be encoded &\n","normalized. Your inference model will be able to process raw images or raw structured\n","data, and will not require users of the model to be aware of the details of e.g. the\n","tokenization scheme used for text, the indexing scheme used for categorical features,\n","whether image pixel values are normalized to `[-1, +1]` or to `[0, 1]`, etc. This is\n","especially powerful if you're exporting\n","your model to another runtime, such as TensorFlow.js: you won't have to\n","reimplement your preprocessing pipeline in JavaScript.\n","\n","If you initially put your preprocessing layers in your `tf.data` pipeline,\n","you can export an inference model that packages the preprocessing.\n","Simply instantiate a new model that chains\n","your preprocessing layers and your training model:\n","\n","```python\n","inputs = keras.Input(shape=input_shape)\n","x = preprocessing_layer(inputs)\n","outputs = training_model(x)\n","inference_model = keras.Model(inputs, outputs)\n","```"]},{"cell_type":"markdown","metadata":{"id":"b41b381d48d4"},"source":["## Quick recipes\n","\n","### Image data augmentation\n","\n","Note that image data augmentation layers are only active during training (similarly to\n","the `Dropout` layer)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T19:46:54.548692Z","iopub.status.busy":"2021-11-12T19:46:54.548102Z","iopub.status.idle":"2021-11-12T19:47:16.817133Z","shell.execute_reply":"2021-11-12T19:47:16.816610Z"},"id":"a3793692e983"},"outputs":[],"source":["# Create a data augmentation stage with horizontal flipping, rotations, zooms\n","data_augmentation = keras.Sequential(\n","    [\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(0.1),\n","        layers.RandomZoom(0.1),\n","    ]\n",")\n","\n","# Load some data\n","(x_train, y_train), _ = keras.datasets.cifar10.load_data()\n","input_shape = x_train.shape[1:]\n","classes = 10"]},{"cell_type":"code","source":["print(x_train.shape[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aC14lUGD-8Qp","executionInfo":{"status":"ok","timestamp":1665641747656,"user_tz":-540,"elapsed":7,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"392f494e-9bfe-4aff-e3cf-bf59b80d577d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["50000\n"]}]},{"cell_type":"code","source":["print(input_shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xXu7CDoY_DMJ","executionInfo":{"status":"ok","timestamp":1665641768481,"user_tz":-540,"elapsed":392,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"db75470d-1ede-4579-ea62-88e2cb00946a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 32, 3)\n"]}]},{"cell_type":"code","source":["# Create a tf.data pipeline of augmented images (and their labels)\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","train_dataset = train_dataset.batch(16).map(lambda x, y: (data_augmentation(x), y))\n","\n","\n","# Create a model and train it on the augmented image data\n","inputs = keras.Input(shape=input_shape)\n","x = layers.Rescaling(1.0 / 255)(inputs)  # Rescale inputs\n","outputs = keras.applications.ResNet50(  # Add the rest of the model\n","    weights=None, input_shape=input_shape, classes=classes\n",")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n","model.fit(train_dataset, steps_per_epoch=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D4FuOXFS-4TY","executionInfo":{"status":"ok","timestamp":1665641949096,"user_tz":-540,"elapsed":26091,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"fe309f4e-84e4-4e5d-e59c-21afa95793ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5/5 [==============================] - 19s 1s/step - loss: 9.5719\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fa976f25250>"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"51d369f0310f"},"source":["You can see a similar setup in action in the example\n","[image classification from scratch](https://keras.io/examples/vision/image_classification_from_scratch/)."]},{"cell_type":"markdown","metadata":{"id":"a79a1c48b2b7"},"source":["### Normalizing numerical features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T19:47:16.823183Z","iopub.status.busy":"2021-11-12T19:47:16.822601Z","iopub.status.idle":"2021-11-12T19:47:23.338185Z","shell.execute_reply":"2021-11-12T19:47:23.338573Z"},"id":"9cc2607a45c8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665645234132,"user_tz":-540,"elapsed":17032,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"22aab22f-ae19-437f-92c3-d931b43698db"},"outputs":[{"output_type":"stream","name":"stdout","text":["(50000, 32, 32, 3)\n","(50000, 3072)\n","(3072,)\n","{'name': 'normalization_5', 'trainable': True, 'batch_input_shape': (None, None), 'dtype': 'float32', 'axis': (-1,), 'mean': None, 'variance': None}\n","1563/1563 [==============================] - 6s 3ms/step - loss: 2.1267\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fa974f97f90>"]},"metadata":{},"execution_count":23}],"source":["# Load some data\n","(x_train, y_train), _ = keras.datasets.cifar10.load_data()\n","print(x_train.shape)\n","x_train = x_train.reshape((len(x_train), -1))\n","print(x_train.shape)\n","input_shape = x_train.shape[1:]\n","print(input_shape)\n","classes = 10\n","\n","# Create a Normalization layer and set its internal state using the training data\n","normalizer = layers.Normalization()\n","normalizer.adapt(x_train)\n","\n","# Create a model that include the normalization layer\n","inputs = keras.Input(shape=input_shape)\n","x = normalizer(inputs)\n","outputs = layers.Dense(classes, activation=\"softmax\")(x)\n","model = keras.Model(inputs, outputs)\n","\n","# Train the model\n","model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n","model.fit(x_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"62685d477010"},"source":["### Encoding string categorical features via one-hot encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T19:47:23.345060Z","iopub.status.busy":"2021-11-12T19:47:23.344442Z","iopub.status.idle":"2021-11-12T19:47:23.403353Z","shell.execute_reply":"2021-11-12T19:47:23.403716Z"},"id":"ae0d2b0405f1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665644392827,"user_tz":-540,"elapsed":683,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"f90927c2-5ec9-4f66-ce6b-672cc210f53d"},"outputs":[{"output_type":"stream","name":"stdout","text":["['[UNK]', 'c', 'b', 'a']\n","tf.Tensor(\n","[[0. 0. 0. 1.]\n"," [0. 0. 1. 0.]\n"," [0. 1. 0. 0.]\n"," [1. 0. 0. 0.]\n"," [1. 0. 0. 0.]\n"," [1. 0. 0. 0.]], shape=(6, 4), dtype=float32)\n"]}],"source":["# Define some toy data\n","data = tf.constant([[\"a\"], [\"b\"], [\"c\"], [\"b\"], [\"c\"], [\"a\"]])\n","\n","# Use StringLookup to build an index of the feature values and encode output.\n","lookup = layers.StringLookup(output_mode=\"one_hot\")\n","lookup.adapt(data)\n","print(lookup.get_vocabulary())\n","\n","# Convert new test data (which includes unknown feature values)\n","test_data = tf.constant([[\"a\"], [\"b\"], [\"c\"], [\"d\"], [\"e\"], [\"\"]])\n","encoded_data = lookup(test_data)\n","print(encoded_data)"]},{"cell_type":"markdown","metadata":{"id":"686aeda532f5"},"source":["Note that, here, index 0 is reserved for out-of-vocabulary values\n","(values that were not seen during `adapt()`).\n","\n","You can see the `StringLookup` in action in the\n","[Structured data classification from scratch](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)\n","example."]},{"cell_type":"markdown","metadata":{"id":"dc8af3e290df"},"source":["### Encoding integer categorical features via one-hot encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T19:47:23.411229Z","iopub.status.busy":"2021-11-12T19:47:23.410616Z","iopub.status.idle":"2021-11-12T19:47:23.472822Z","shell.execute_reply":"2021-11-12T19:47:23.473282Z"},"id":"75f3d6af4522","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665644298811,"user_tz":-540,"elapsed":5,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"66a4fbdf-d876-49b0-b8e6-2616768a8900"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 1568 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fa9752d9f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["[-1, 20, 10, 30, 0]\n","tf.Tensor(\n","[[0. 0. 1. 0. 0.]\n"," [0. 0. 1. 0. 0.]\n"," [0. 1. 0. 0. 0.]\n"," [1. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1.]], shape=(6, 5), dtype=float32)\n"]}],"source":["# Define some toy data\n","data = tf.constant([[10], [20], [20], [10], [30], [0]])\n","\n","# Use IntegerLookup to build an index of the feature values and encode output.\n","lookup = layers.IntegerLookup(output_mode=\"one_hot\")\n","lookup.adapt(data)\n","print(lookup.get_vocabulary())\n","\n","# Convert new test data (which includes unknown feature values)\n","test_data = tf.constant([[10], [10], [20], [50], [60], [0]])\n","encoded_data = lookup(test_data)\n","print(encoded_data)"]},{"cell_type":"markdown","metadata":{"id":"da5a6be487be"},"source":["Note that index 0 is reserved for missing values (which you should specify as the value\n","0), and index 1 is reserved for out-of-vocabulary values (values that were not seen\n","during `adapt()`). You can configure this by using the `mask_token` and `oov_token`\n","constructor arguments  of `IntegerLookup`.\n","\n"]},{"cell_type":"markdown","source":["인덱스 0은 누락된 값(빈 문자열 \"\"로 지정해야 함)을 위해 예약되고, 인덱스 1은 어휘를 벗어난 값(adapt() 동안 표시되지 않은 값)을 위해 예약되어 있습니다. mask_token 및 StringLookup의 oov_token 생성자 인수를 사용하여 이를 구성할 수 있습니다.\n","\n","mask 토큰으로 문장 중간의 빈 칸 예측"],"metadata":{"id":"lISRYKSUHyki"}},{"cell_type":"markdown","source":["You can see the `IntegerLookup` in action in the example\n","[structured data classification from scratch](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)."],"metadata":{"id":"Q-7uRwlxH0wi"}},{"cell_type":"markdown","metadata":{"id":"8fbfaa6ab3e2"},"source":["### Applying the hashing trick to an integer categorical feature\n","\n","If you have a categorical feature that can take many different values (on the order of\n","10e3[10000] or higher), where each value only appears a few times in the data,\n","it becomes impractical and ineffective to index and one-hot encode the feature values.\n","Instead, it can be a good idea to apply the \"hashing trick\": hash the values to a vector\n","of fixed size. This keeps the size of the feature space manageable, and removes the need\n","for explicit indexing."]},{"cell_type":"markdown","source":["여러 다른 값(10000 이상)을 사용할 수 있는 범주형 특성의 각 값이 데이터에서 몇 번만 나타나는 경우, 특성 값을 인덱싱하고 원-핫 인코딩하는 것은 비실용적이고 비효율적입니다. 대신, \"해싱 트릭\"을 적용하는 것이 좋습니다. 값을 고정된 크기의 벡터로 해싱합니다. 이는 특성 공간의 크기를 관리 가능한 상태로 유지하고 명시적 인덱싱의 필요성을 제거합니다."],"metadata":{"id":"chbVlYXuN5hC"}},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T19:47:23.480156Z","iopub.status.busy":"2021-11-12T19:47:23.479497Z","iopub.status.idle":"2021-11-12T19:47:23.487609Z","shell.execute_reply":"2021-11-12T19:47:23.487998Z"},"id":"8f6c1f84c43c","outputId":"1f282796-3f51-490d-9096-4aa515cec0b1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665706893248,"user_tz":-540,"elapsed":703,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(10000, 64)\n"]}],"source":["# Sample data: 10,000 random integers with values between 0 and 100,000\n","data = np.random.randint(0, 100000, size=(10000, 1))\n","\n","# Use the Hashing layer to hash the values to the range [0, 64]\n","hasher = layers.Hashing(num_bins=64, salt=1337)\n","\n","# Use the CategoryEncoding layer to multi-hot encode the hashed values\n","encoder = layers.CategoryEncoding(num_tokens=64, output_mode=\"multi_hot\")\n","encoded_data = encoder(hasher(data))\n","print(encoded_data.shape)"]},{"cell_type":"markdown","source":["암호학에서 솔트는 데이터, 비밀번호, 통과암호를 해시 처리하는 단방향 함수의 추가 입력으로 사용되는 랜덤 데이터이다"],"metadata":{"id":"dhH7wMVONnLa"}},{"cell_type":"markdown","metadata":{"id":"df69b434d327"},"source":["### Encoding text as a sequence of token indices\n","\n","This is how you should preprocess text to be passed to an `Embedding` layer."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T19:47:23.497851Z","iopub.status.busy":"2021-11-12T19:47:23.497194Z","iopub.status.idle":"2021-11-12T19:47:27.040607Z","shell.execute_reply":"2021-11-12T19:47:27.041017Z"},"id":"361b561bc88b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665707690934,"user_tz":-540,"elapsed":487,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"dcb1111d-baed-46e1-84e8-12325cb85ab0"},"outputs":[{"output_type":"stream","name":"stdout","text":["['', '[UNK]', 'the', 'side', 'you', 'with', 'will', 'wider', 'them', 'than', 'sky', 'put', 'other', 'one', 'is', 'for', 'ease', 'contain', 'by', 'brain', 'beside', 'and']\n"]}],"source":["# Define some text data to adapt the layer\n","adapt_data = tf.constant(\n","    [\n","        \"The Brain is wider than the Sky\",\n","        \"For put them side by side\",\n","        \"The one the other will contain\",\n","        \"With ease and You beside\",\n","    ]\n",")\n","\n","# Create a TextVectorization layer\n","text_vectorizer = layers.TextVectorization(output_mode=\"int\")\n","# Index the vocabulary via `adapt()`\n","text_vectorizer.adapt(adapt_data)\n","print(text_vectorizer.get_vocabulary())"]},{"cell_type":"code","source":["# Try out the layer\n","print(\n","    \"Encoded text:\\n\", text_vectorizer([\"The Brain is deeper than the sea\"]).numpy(),\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_Nzism-4Hl_","executionInfo":{"status":"ok","timestamp":1665707693974,"user_tz":-540,"elapsed":3,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"f8501743-86ce-4eb7-9d43-9d8b788f0473"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded text:\n"," [[ 2 19 14  1  9  2  1]]\n"]}]},{"cell_type":"code","source":["# Create a simple model\n","inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","x = layers.Embedding(input_dim=text_vectorizer.vocabulary_size(), output_dim=16)(inputs)\n","x = layers.GRU(8)(x)\n","outputs = layers.Dense(1)(x)\n","model = keras.Model(inputs, outputs)\n","\n","\n","# Create a labeled dataset (which includes unknown tokens)\n","train_dataset = tf.data.Dataset.from_tensor_slices(\n","    ([\"The Brain is deeper than the sea\", \"for if they are held Blue to Blue\"], [1, 0])\n",")\n","\n","# Preprocess the string inputs, turning them into int sequences\n","train_dataset = train_dataset.batch(2).map(lambda x, y: (text_vectorizer(x), y))\n","# Train the model on the int sequences\n","print(\"\\nTraining model...\")\n","model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n","model.fit(train_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XBIO7Mr84B6X","executionInfo":{"status":"ok","timestamp":1665707704746,"user_tz":-540,"elapsed":7749,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"42289a2c-a477-451a-dc41-89db0e728952"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training model...\n","1/1 [==============================] - 7s 7s/step - loss: 0.5059\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc2501a7790>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# For inference, you can export a model that accepts strings as input\n","inputs = keras.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","outputs = model(x)\n","end_to_end_model = keras.Model(inputs, outputs)\n","\n","# Call the end-to-end model on test data (which includes unknown tokens)\n","print(\"\\nCalling end-to-end model on test string...\")\n","test_data = tf.constant([\"The one the other will absorb\"])\n","test_output = end_to_end_model(test_data)\n","print(\"Model output:\", test_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8wtHqY85jUj","executionInfo":{"status":"ok","timestamp":1665707797912,"user_tz":-540,"elapsed":3,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"dc56dd5e-c51a-42b9-8eea-53fe15715a09"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Calling end-to-end model on test string...\n","Model output: tf.Tensor([[0.02756127]], shape=(1, 1), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"e725dbcae3e4"},"source":["You can see the `TextVectorization` layer in action, combined with an `Embedding` mode,\n","in the example\n","[text classification from scratch](https://keras.io/examples/nlp/text_classification_from_scratch/).\n","\n","Note that when training such a model, for best performance, you should always\n","use the `TextVectorization` layer as part of the input pipeline."]},{"cell_type":"markdown","source":["처음부터 텍스트 분류 예에서 Embedding 모드와 결합된 TextVectorization 레이어가 동작하는 것을 볼 수 있습니다.\n","\n","이러한 모델을 훈련할 때 최상의 성능을 위해 TextVectorization 레이어를 입력 파이프라인(위의 텍스트 분류 예제에서 수행한 작업)의 일부로 사용해야 합니다."],"metadata":{"id":"w-9eyVbvgOdL"}},{"cell_type":"markdown","metadata":{"id":"28c2f2ff61fb"},"source":["### Encoding text as a dense matrix of ngrams with multi-hot encoding\n","\n","This is how you should preprocess text to be passed to a `Dense` layer."]},{"cell_type":"markdown","source":["다음은 Dense 레이어로 전달될 텍스트를 전처리하는 방법입니다."],"metadata":{"id":"de1QsvmtgQEi"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T19:47:27.051048Z","iopub.status.busy":"2021-11-12T19:47:27.050405Z","iopub.status.idle":"2021-11-12T19:47:27.531477Z","shell.execute_reply":"2021-11-12T19:47:27.531837Z"},"id":"7bae1c223cd8","outputId":"3d47ed1b-d96b-4c57-d946-0c283d8b7c1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:5 out of the last 1567 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f1b9c5c5290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"name":"stdout","output_type":"stream","text":["Encoded text:\n"," [[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n","  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]]\n","\n","Training model...\n"]},{"name":"stdout","output_type":"stream","text":["\r","1/1 [==============================] - ETA: 0s - loss: 1.0046"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","1/1 [==============================] - 0s 231ms/step - loss: 1.0046\n"]},{"name":"stdout","output_type":"stream","text":["\n","Calling end-to-end model on test string...\n","Model output: tf.Tensor([[-0.54753447]], shape=(1, 1), dtype=float32)\n"]}],"source":["# Define some text data to adapt the layer\n","adapt_data = tf.constant(\n","    [\n","        \"The Brain is wider than the Sky\",\n","        \"For put them side by side\",\n","        \"The one the other will contain\",\n","        \"With ease and You beside\",\n","    ]\n",")\n","# Instantiate TextVectorization with \"multi_hot\" output_mode\n","# and ngrams=2 (index all bigrams)\n","text_vectorizer = layers.TextVectorization(output_mode=\"multi_hot\", ngrams=2)\n","# Index the bigrams via `adapt()`\n","text_vectorizer.adapt(adapt_data)\n","\n","# Try out the layer\n","print(\n","    \"Encoded text:\\n\", text_vectorizer([\"The Brain is deeper than the sea\"]).numpy(),\n",")\n","\n","# Create a simple model\n","inputs = keras.Input(shape=(text_vectorizer.vocabulary_size(),))\n","outputs = layers.Dense(1)(inputs)\n","model = keras.Model(inputs, outputs)\n","\n","# Create a labeled dataset (which includes unknown tokens)\n","train_dataset = tf.data.Dataset.from_tensor_slices(\n","    ([\"The Brain is deeper than the sea\", \"for if they are held Blue to Blue\"], [1, 0])\n",")\n","\n","# Preprocess the string inputs, turning them into int sequences\n","train_dataset = train_dataset.batch(2).map(lambda x, y: (text_vectorizer(x), y))\n","# Train the model on the int sequences\n","print(\"\\nTraining model...\")\n","model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n","model.fit(train_dataset)\n","\n","# For inference, you can export a model that accepts strings as input\n","inputs = keras.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","outputs = model(x)\n","end_to_end_model = keras.Model(inputs, outputs)\n","\n","# Call the end-to-end model on test data (which includes unknown tokens)\n","print(\"\\nCalling end-to-end model on test string...\")\n","test_data = tf.constant([\"The one the other will absorb\"])\n","test_output = end_to_end_model(test_data)\n","print(\"Model output:\", test_output)"]},{"cell_type":"markdown","metadata":{"id":"336a4d3426ed"},"source":["### Encoding text as a dense matrix of ngrams with TF-IDF weighting\n","\n","This is an alternative way of preprocessing text before passing it to a `Dense` layer."]},{"cell_type":"markdown","source":["다음은 Dense 레이어로 전달하기 전에 텍스트를 전처리하는 또 다른 방법입니다."],"metadata":{"id":"7IDhV-tcgTAr"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-12T19:47:27.542183Z","iopub.status.busy":"2021-11-12T19:47:27.541552Z","iopub.status.idle":"2021-11-12T19:47:28.092695Z","shell.execute_reply":"2021-11-12T19:47:28.093142Z"},"id":"5b6c0fec928e","outputId":"2c7e810a-7ba1-46a4-f388-5bd425c137eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:6 out of the last 1568 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f1b9f6eae60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"name":"stdout","output_type":"stream","text":["Encoded text:\n"," [[5.461647  1.6945957 0.        0.        0.        0.        0.\n","  0.        0.        0.        0.        0.        0.        0.\n","  0.        0.        1.0986123 1.0986123 1.0986123 0.        0.\n","  0.        0.        0.        0.        0.        0.        0.\n","  1.0986123 0.        0.        0.        0.        0.        0.\n","  0.        1.0986123 1.0986123 0.        0.        0.       ]]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Training model...\n"]},{"name":"stdout","output_type":"stream","text":["\r","1/1 [==============================] - ETA: 0s - loss: 4.4868"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r","1/1 [==============================] - 0s 239ms/step - loss: 4.4868\n"]},{"name":"stdout","output_type":"stream","text":["\n","Calling end-to-end model on test string...\n","Model output: tf.Tensor([[0.25670475]], shape=(1, 1), dtype=float32)\n"]}],"source":["# Define some text data to adapt the layer\n","adapt_data = tf.constant(\n","    [\n","        \"The Brain is wider than the Sky\",\n","        \"For put them side by side\",\n","        \"The one the other will contain\",\n","        \"With ease and You beside\",\n","    ]\n",")\n","# Instantiate TextVectorization with \"tf-idf\" output_mode\n","# (multi-hot with TF-IDF weighting) and ngrams=2 (index all bigrams)\n","text_vectorizer = layers.TextVectorization(output_mode=\"tf-idf\", ngrams=2)\n","# Index the bigrams and learn the TF-IDF weights via `adapt()`\n","\n","with tf.device(\"CPU\"):\n","    # A bug that prevents this from running on GPU for now.\n","    text_vectorizer.adapt(adapt_data)\n","\n","# Try out the layer\n","print(\n","    \"Encoded text:\\n\", text_vectorizer([\"The Brain is deeper than the sea\"]).numpy(),\n",")\n","\n","# Create a simple model\n","inputs = keras.Input(shape=(text_vectorizer.vocabulary_size(),))\n","outputs = layers.Dense(1)(inputs)\n","model = keras.Model(inputs, outputs)\n","\n","# Create a labeled dataset (which includes unknown tokens)\n","train_dataset = tf.data.Dataset.from_tensor_slices(\n","    ([\"The Brain is deeper than the sea\", \"for if they are held Blue to Blue\"], [1, 0])\n",")\n","\n","# Preprocess the string inputs, turning them into int sequences\n","train_dataset = train_dataset.batch(2).map(lambda x, y: (text_vectorizer(x), y))\n","# Train the model on the int sequences\n","print(\"\\nTraining model...\")\n","model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n","model.fit(train_dataset)\n","\n","# For inference, you can export a model that accepts strings as input\n","inputs = keras.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","outputs = model(x)\n","end_to_end_model = keras.Model(inputs, outputs)\n","\n","# Call the end-to-end model on test data (which includes unknown tokens)\n","print(\"\\nCalling end-to-end model on test string...\")\n","test_data = tf.constant([\"The one the other will absorb\"])\n","test_output = end_to_end_model(test_data)\n","print(\"Model output:\", test_output)"]},{"cell_type":"markdown","metadata":{"id":"143ce01c5558"},"source":["## Important gotchas\n","\n","### Working with lookup layers with very large vocabularies\n","\n","You may find yourself working with a very large vocabulary in a `TextVectorization`, a `StringLookup` layer,\n","or an `IntegerLookup` layer. Typically, a vocabulary larger than 500MB would be considered \"very large\".\n","\n","In such case, for best performance, you should avoid using `adapt()`.\n","Instead, pre-compute your vocabulary in advance\n","(you could use Apache Beam or TF Transform for this)\n","and store it in a file. Then load the vocabulary into the layer at construction\n","time by passing the filepath as the `vocabulary` argument.\n","\n","\n"]},{"cell_type":"markdown","source":["TextVectorization, StringLookup 계층 또는 IntegerLookup 계층에서 매우 방대한 어휘로 작업하는 여러분 자신을 발견할 수 있습니다. 일반적으로 500MB보다 큰 어휘는 \"매우 큰\" 것으로 간주됩니다.\n","\n","이러한 경우 최상의 성능을 위해 adapt() 사용을 피해야 합니다. 대신 사전에 어휘를 미리 계산하고(이를 위해 Apache Beam 또는 TF Transform을 사용할 수 있음) 파일에 저장합니다. 그런 다음 파일 경로를 어휘 인수로 전달하여 구성 시 레이어에 어휘를 로드합니다."],"metadata":{"id":"SUi7OSxKgd3i"}},{"cell_type":"markdown","source":["### Using lookup layers on a TPU pod or with `ParameterServerStrategy`.\n","\n","There is an outstanding issue that causes performance to degrade when using\n","a `TextVectorization`, `StringLookup`, or `IntegerLookup` layer while\n","training on a TPU pod or on multiple machines via `ParameterServerStrategy`.\n","This is slated to be fixed in TensorFlow 2.7."],"metadata":{"id":"UZliHyQsgiYK"}},{"cell_type":"markdown","source":["TPU 포드 또는 ParameterServerStrategy를 통해 여러 시스템에서 교육하는 동안 TextVectorization, StringLookup 또는 IntegerLookup 레이어를 사용할 때 성능이 저하되는 미해결 문제가 있습니다. 이것은 TensorFlow 2.7에서 수정될 예정입니다."],"metadata":{"id":"hmpCOOOBgjDD"}}],"metadata":{"colab":{"collapsed_sections":[],"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}