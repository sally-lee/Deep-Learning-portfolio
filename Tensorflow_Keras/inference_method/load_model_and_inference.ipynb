{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPtuszSD1nagDOHvNaku7sk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/google_drive')"],"metadata":{"id":"xuKF1uoQEevW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -U \"tensorflow>=2.5\""],"metadata":{"id":"QFLtQEKREfLk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pathlib\n","\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone https://github.com/tensorflow/models"],"metadata":{"id":"CRZ0e4rMEi9d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","sudo apt install -y protobuf-compiler\n","cd /content/models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cd /content\n","git clone https://github.com/cocodataset/cocoapi.git\n","cd /content/cocoapi/PythonAPI\n","make\n","cp -r pycocotools /content/models/research/\n","cd /content/models/research/\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install .\n","cd /content"],"metadata":{"id":"U2MA5VZ-EkC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLP51VpAEU2q"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n","import time\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","%matplotlib inline"]},{"cell_type":"code","source":["def load_image_into_numpy_array(path):\n","    \"\"\"Load an image from file into a numpy array.\n","\n","    Puts image into numpy array to feed into tensorflow graph.\n","    Note that by convention we put it into a numpy array with shape\n","    (height, width, channels), where channels=3 for RGB.\n","\n","    Args:\n","      path: the file path to the image\n","\n","    Returns:\n","      uint8 numpy array with shape (img_height, img_width, 3)\n","    \"\"\"\n","    return np.array(Image.open(path))"],"metadata":{"id":"kP81ZNs2Ec00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PATH_TO_MODEL_DIR = \"/content/google_drive/MyDrive/Tensorflow_OD_API/efficientdet_d1_coco17_tpu-32/workspace/output_model/retrain1\"\n","PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\""],"metadata":{"id":"PQ1TxgfZEcu9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Loading model...', end='')\n","start_time = time.time()\n","\n","# Load saved model and build the detection function\n","detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print('Done! Took {} seconds'.format(elapsed_time))"],"metadata":{"id":"BcHxcMjnEcm1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["category_index = label_map_util.create_category_index_from_labelmap(\"/content/google_drive/MyDrive/Tensorflow_OD_API/efficientdet_d1_coco17_tpu-32/workspace/annotations/pet_label_map.pbtxt\",use_display_name=True)"],"metadata":{"id":"zu7RnbqFEsrc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imageDir2 = \"/content/google_drive/MyDrive/dataset/online_pet\"\n","IMAGE_PATHS = [imageDir2 + \"/\" + f for f in os.listdir(imageDir2) if f[-4:] in ['.jpg','.jpeg','.png']]\n","IMAGE_PATHS = IMAGE_PATHS[0:16]"],"metadata":{"id":"ogpg0HqyEspV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for image_path in IMAGE_PATHS:\n","\n","    print('Running inference for {}... '.format(image_path), end='')\n","\n","    image_np = load_image_into_numpy_array(image_path)\n","\n","    # Things to try:\n","    # Flip horizontally\n","    # image_np = np.fliplr(image_np).copy()\n","\n","    # Convert image to grayscale\n","    # image_np = np.tile(\n","    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n","\n","    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","    input_tensor = tf.convert_to_tensor(image_np)\n","    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","    input_tensor = input_tensor[tf.newaxis, ...]\n","\n","    # input_tensor = np.expand_dims(image_np, 0)\n","    detections = detect_fn(input_tensor)\n","\n","    # All outputs are batches tensors.\n","    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","    # We're only interested in the first num_detections.\n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                   for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    image_np_with_detections = image_np.copy()\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np_with_detections,\n","          detections['detection_boxes'],\n","          detections['detection_classes'],\n","          detections['detection_scores'],\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=200,\n","          min_score_thresh=.30,\n","          agnostic_mode=False)\n","\n","    plt.figure()\n","    plt.figure(figsize=(9,9))\n","    plt.imshow(image_np_with_detections)\n","    print('Done')\n","plt.show()"],"metadata":{"id":"DDqvwIU5EsnV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"C9krZVo4Ese3"},"execution_count":null,"outputs":[]}]}